---
title: "Optane DC PMM, Persimmon and SplitFS"
author: Ramneek Kaur <rk3994@nyu.edu>
---
# Optane Persistent Memory Module
## Introduction 

Optane FC Persistent Memory Module is a scalable nonvolatile memory DIMMs that supports byte-granularity accesses with access times on the order of DRAM and also provides data storage that can survive the power outages.

In this research paper author experiments on Optane DC PMM as main memory and persistent storage to measure performance and flexibility of the new technology

## Motivation 
In a memory hierarchy, Optane DC memory occupies a tier between main memory (DRAM) and persistence storage  (SSDs). It gives a unique position to configure and use Optane DC memory as a main memory and persistence memory.  

Optane DC memory can be configured to run in cached or uncached mode. The author experiments with both of it in order to understand the new memory device performance and point of future work areas.

## Approach

Optane DC PMM has two modes
Memory - In this Optane memory is used to expand main memory capacity without persistence. It serves as a direct mapped cache with block size of 64 bytes. Alternatively known as cached.
App Directed Mode - In this Optane memory is used for building a storage system. The system installs a file system to manage the memory and allows applications to directly use the memory.  

### Basic Performance Benchmark
The author found out that latency of Optane memory is higher than DRAM for both read and write operation.
The bandwidth of read-write operation increases quickly until 256B size and slowly climbs upto 1.5GB/s. This quick increase is a result of Optane memory’s internal 256B block size and memory write requires minimum 256B.     

### As a Main Memory
In this experiment, the author replaced DRAM with cached and uncached versions of the Optane DC PMM. The uncached version of Optane DC saw the highest 61% drop in the performance while the cached version saw 15% performance reduction for floating point operations. 

The author also showed that normal DRAM can be used to hide the Optane DC memory’s latency which is useful for large sized databases.

### As a Persistent Storage
The author used Optane memory without DRAM cache as the storage system and experiment found out that Oprane DC PMMs provide a big boost for RW  performance compared to both SATA SSDs and Optane-based SSDs. Modifying an application to use memory-mapped Optane DC yields the highest performance. 

## Trade Offs
Although Optane memory can provide large memory with little overhead, only few applications like data processing can make use of it. For more general use cases, fast memory is more beneficial than the slower and large ones.

To achieve higher performance with persistent storage, applications need to be updated to use memory-mapped modules. It can be a bottle-neck for faster adoption of a memory.

## Open questions
* What is the acceptable overhead to include Optane DC PMM as the DRAM?
* How can Optane DC PMM achieve higher performance as persistent storage without requiring applications to use memory-mapped modules.   

# Persimmon
## Introduction and Motivation
The need for in-memory storage systems have grown larger due to their high performance and ability to process transactions within microseconds which is required to keep up with the network speed as datacenter network is becoming faster and kernel bypass removes OS bottlenecks. 

Distributed memory storage systems is one of the most famous in-memory storage systems which is crucial because of its low latency requirements. It is fast and provides consistency and fault-tolerance. The major drawbacks of distributed in-memory storage systems are as follows:
* Expensive recovery of data
* Data loss is always at risk
* Nondurable

Persistent memory (PM) was introduced to overcome some of the problems of in-memory storage systems, which provides the possibility of building fast, persistent in-memory storage. Persistent memory is durable, provides high performance closer to DRAM and has availability in large sizes. PM based memory services has some major drawbacks as well, as mentioned below:
* PM is often built from scratch to provide correctness and high performance while ensuring failure atomicity.
* High performance overhead.
* Lack of crash consistency.

Persimmon offers a promising solutions to overcome the drawbacks of Persistent memory by converting existing distributed in-memory storage systems into persistent in-memory storage to achieve durability, low cost, crash consistent, and minimal modification. 

## Approach

Traditionally, distributed in-memory storage systems are designed as RPC-processing state machines but Persimmon introduces a new abstraction called persistent state machines (PSM). PSM revolves around an idea that no side effects will be lost when an operation on PSM returns. PSM operations are failure atomic which means if an operation does not return before a crash then the operation will be applied again or it won’t be applied at all. To ensure failure atomicity, Persimmon performs shadow executions in which it switches to a dynamically instrumented version of the application for running the PSM. 

The three main goals Persimmon design achieve are:
* Minimal Design change: The current in-memory storage systems have the biggest advantage of low latency but it requires high modification. Goal here is to keep the optimization without major modifications. 
* Strong Guarantees: Persimmon's second goal is to overcome major annmoly of PM by providing crash consistency.
* Good Performance: Last goal of Persimmon is to provide fast recovery and less than microsecond latency overhead on in-memory systems with no persistence. 

Overview of Working: Persimmon keeps two state copies, one in DRAM another one in PM to minimize performance overhead of accessing PM on the request processing path. When any application invokes Persimmon operation, it first executes operation on DRAM and if the operation is read only then Persimmon returns. If the operation invoked by any application is read-write then it logs the operations then returns. In case of failure, Persimmon recovers PSM from persistent log. Persimmon also keeps PSM up to date in PM to make a fast recovery. The state machine abstraction allows Persimmon to update the PM snapshot with a crash consistent shadow execution of each PSM operation, which is then removed from the log. In case of recovery, the snapshots in PM are copied to DRAM by Persimmon and then all the persistent logs are processed and finally restarts the application. In order to reduce the recovery time, shadow executions are performed on another CPU. 

## Trade Offs
Persimmon is an efficient way to provide crash consistency to Persistent memory by providing high speed recovery at low cost. However, Persimmon does not support multi threaded applications that apply operations at the same time. For many applications multi threading is a way to provide more throughput and it would be challenging to port multi threaded applications to Persimmon.



# SpitFS

## Introduction and Motivation
SpitFS is a file system introduced to overcome the software overhead problem in Persistent memory (PM). Software overhead is a major problem in PM and many solutions were found to overcome it, such as state-of-the-art PM file systems, NOVA PM file systems, ext4 DAX and so on. Despite all the proposed solutions, file system data operation especially writes still have major overhead issues. SpiltFS resolves these issues by splitting the responsibilities among a user-space library file system and an existing kernel PM file system. SpitFS reduces the software overhead significantly compared to other file systems. 


## Approaches
SpitFS is based on a novel split architecture in which the user-space library file system handles data operations while a kernel PM file system (ext4 DAX) handles metadata operations. File system operation which modifies the metadata, such as open(), close() and append() are known as metadata operations. The key factor in SpitFS file system is about careful splitting of responsibilities between the user-space and kernel components, and the semantics provided to applications. 

The major goals of SpitFS design achieves as follows:
* Low software overhead: SpitFS aims to reduce software overhead especially for write and append operation.
* Transparency: No modification is required by SplitFS in order to provide low software overhead and good performance. 
* Minimal data copying and write IO: SplitFS aims to avoid copying of data within the file system and reducing the number of writes.
* Low implementation complexity: SpitFS objective is to use prevailing software like ext4 DAX which minimizes the codes needed to be written.
* Flexible guarantees: SplitFS aims to provide applications with a choice of crash-consistency guarantees to choose from.
* SpiltFS provides three different modes known as POSIX, sync and strict, each with varying guarantees and allows different applications to use different modes. 

# Trade-Offs
SplitFS increases the performance of applications twice as compared to ext4 and NOVA. Since SpiltFS is based on open ext4 DAX, all the metadata operations are routed through ext4 DAX which at the end requires high write IO for metadata operations and results in high software overhead. 






